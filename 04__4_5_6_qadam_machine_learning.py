# -*- coding: utf-8 -*-
"""04_ 4-5-6-qadam_Machine_learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17o0NuyjVz9y1bVbwvzc8dMcpgmMgGxRa

# **4-qadam Machine Learning**
"""

import pandas as pd
import numpy as np
import sklearn as sk

url = "https://github.com/ageron/handson-ml2/blob/master/datasets/housing/housing.csv?raw=true"
df = pd.read_csv(url)

df

from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(df, test_size=0.2, random_state=50)

X_train = train_set.drop("median_house_value", axis=1)
y = train_set["median_house_value"].copy()

X_num = X_train.drop("ocean_proximity", axis=1)

"""## Pipeline quramiz"""

from sklearn.base import BaseEstimator, TransformerMixin

# bizga kerak ustunlar indexlari
rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6

class CombinedAttributesadder(BaseEstimator, TransformerMixin):
  def __init__(self, add_bedrooms_per_room=True):
    self.add_bedrooms_per_room = add_bedrooms_per_room
  def fit(self, X, y=None):
    return self # bizning funksiyamiz faqat transformer. estimator emas
  def transform(self, X):
    rooms_per_household = X[:, rooms_ix] / X[:, households_ix]
    population_per_household = X[:, population_ix] / X[:, households_ix]
    if self.add_bedrooms_per_room:  # add_bedrooms_per_room ustuni ixtiyoriy bo'ladi
      bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]
      return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
    else:
      return np.c_[X, rooms_per_household, population_per_household]

"""## Sonli ustunlar uchun"""

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="median")),
    ('atter_adder', CombinedAttributesadder(add_bedrooms_per_room= True)),
    ('std_scaler', StandardScaler())
])

"""## Matnli ustunlar uchun"""

from sklearn.compose import ColumnTransformer

num_attribs = list(X_num)
cat_attribs = ["ocean_proximity"]

full_pipeline = ColumnTransformer([
    ("num", num_pipeline, num_attribs),
    ("cat", OneHotEncoder(), cat_attribs)
])

X_prepared = full_pipeline.fit_transform(X_train)

X_prepared

X_train
# Bu yuqorida yaratgan median_house_value ustunini tashlab yaratgan ustunimiz

"""## Ma'lumotlar ML uchun tayyor.

## **Machine Learning**
"""

### Linear Regression

"""## Linear Regression - Chiziqli **regressiya**
## sklearn tarkibidagi LinearRegression klassidan yangi model yaratamiz.
"""

from sklearn.linear_model import LinearRegression

LR_model = LinearRegression()

LR_model.fit(X_prepared, y)

# Ushbu kod parchasi Sklearn kutubxonasidan LinearRegression modelini import qiladi, uni LR_model
# o'zgaruvchisiga o'rnatadi va keyin X_prepared (tayyorlangan xususiyatlar) hamda y (maqsad qiymatlar)
# yordamida modelni o'qitadi. Ya'ni, model kiritilgan ma'lumotlar asosida natijalarni taxmin qilishni o'rganadi.

"""LinearRegression bu estimator. Estimatorlar ma'lumotlarni qabul qilib oladi va .fit() metodi yordamida ulardan basorat qilishni o'rganadi (machine learning)

TAMOM! Machine Learning tugadi! bor yo'g'i 3 qator kod bilan biz kompyuterga uylarni narxini bashorat qilishni o'rgatdik.

Modelni qanday qilib tekshirib ko'rishimiz mumkin? housing datasetdan biror qatorni modelga beramiz va chiqqan natijani bizdagi bor natija (label) bilan solishtiramiz.
"""

test_data = X_train.sample(10)
test_data
# test_data ga X_train dan taxminiy 10 tasini saqlab chiqarayabmiz

test_label = y.loc[test_data.index]
test_label
# test_label ga yuqoridagi test_data ning index lari va median_house_value yani narxi ham saqlab chiqarildi

test_data_prepared = full_pipeline.transform(test_data)
predicted_labels = LR_model.predict(test_data_prepared)
predicted_labels
# test_data ni pipeline.transform dan o'tkazildi va test_data_prepared ga saqlandi
# Hamda ML qismida o'tkazilib predicted_labels ga saqlandi

"""## Bu qiymatlarni yuqoridagi asl median_house_value qiymatlari bilan solishtirishimiz mumkin

## Tushunarliroq ko'rish uchun bashorat qilganimiz va asl median_house_value ustuni yani uni test lebel ga saqlagan qiymatlarimizni aniqlik darajasini solishtirib ko'rishimiz mumkin
"""

pd.DataFrame({'Bashorat_qilindi': predicted_labels, 'Asl_qiymat': test_label})

# Buni shunchaki tekshirib ko'rdik bir nechta qatorlar bilan
# test_set qisimlarni ML ga hali kiritmaganligimiz sababli yuqori aniqlikda natija olaolmadik

"""# **NEW SECTION**

# **5**-**QADAM**.

# **Modelni baholash**
"""

test_set

X_test = test_set.drop('median_house_value', axis=1)
X_test

y_test = test_set['median_house_value'].copy()
y_test

X_test_prepapred = full_pipeline.transform(X_test)

y_predicted = LR_model.predict(X_test_prepapred)

y_predicted

pd.DataFrame({'Bashorat_qilindi': y_test, 'Asl_qiymat': y_predicted})
# Barchasini ham tekshirib ko'rdik va solishtirib ko'ryabmiz

"""## mean absolute error yani bu bilan o'rtacha qancha hato bo'layotganligini aniqlashimiz mumkin
## Avvalgi darslarda mean absolute error bilan tanishganmiz endi uni hisoblaymiz
"""

from sklearn.metrics import mean_absolute_error

mean_absolute_error(y_test, y_predicted)

print(f"Mean absolute error:,({mean_absolute_error(y_test, y_predicted)}) $ yani 49_392 dollar ekan o'rtacha xato")

"""## Endi o'rtacha kvadrat xatoligini tekshirib ko'ramiz"""

# Hamda buni oxirida kvadrat yani ildizdan ham chiqarib yuborishimiz kerak
from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_test, y_predicted)

print("RMSE=", np.sqrt(mse))

# Bunda o'rtacha kvadrat xatoligi 67_880 $ ni ko'rsatmoqda

"""Model aniqligini oshirish uchun yagona, universal yechim yo'q. Qilib ko'rishingiz mumkin bo'lgan ishlar:

Yaxhsiroq paramterlar topish
Yaxhsiroq model (algoritm) tanlash
Ko'proq ma'lumot yig'ish va hokazo.
Biz hozir boshqa model bilan sinab ko'ramiz.

## from sklearn.linear_model import LinearRegression

## LR_model = LinearRegression()

## Ko'rib turganimizdek LinearRegression dan yuqori darajada aniqlik chiqmadi shuning uchun pastda boshqa algoritmdan ham foydalanib ko'ramiz

## Shuningdek ML da boshqa algoritmlar ham ko'p hisoblanadi

# **NEW SECTION**

# **Modelni baholash.**

# **Random Forest.**
"""

from sklearn.ensemble import RandomForestRegressor

RF_model = RandomForestRegressor()
RF_model.fit(X_prepared, y)

y_predicted = RF_model.predict(X_test_prepapred)

from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_test, y_predicted)

print("RMSE=", np.sqrt(mse))

"""## Demak ko'rishimiz mumkin yuqorida LinearRegression da mean_squared_error bu 67_880 $ edi.

## Bunda RandomForestRegressor da  mean_squared_error ni hisoblaganimizda 50_281 $ xatolik chiqdi

## Yani nisbatan xatolar kamroq

## **DecisionTree**
"""

from sklearn.tree import DecisionTreeRegressor
Tree_model = DecisionTreeRegressor()
Tree_model.fit(X_prepared, train_set["median_house_value"])

y_predicted = Tree_model.predict(X_test_prepapred)

lin_mse = mean_squared_error(y_test, y_predicted)
# RMSE hisoblaymiz
lin_rmse = np.sqrt(lin_mse)
print(lin_rmse)

"""# **NEW SECTION**

# **Modelni baholash.**

# **Cross-validation**
"""

x = df.drop('median_house_value', axis=1)
y = df['median_house_value'].copy()
# Bularni yana qayatdan x va y ga saqlab oldik

x_prepared = full_pipeline.fit_transform(x)

from sklearn.model_selection import cross_val_score

mse_scores = cross_val_score(LR_model, x_prepared, y, scoring='neg_mean_squared_error', cv=10)
mse_scores
# Ushbu kod cross_val_score funksiyasidan foydalanib, LinearRegression modelini (LR_model) x_prepared xususiyatlari
# va y maqsad qiymatlari yordamida baholaydi. Bu jarayon 10 ta turli bo'linmada amalga oshiriladi (cv=10), modelning
# har bir bo'linmada o'rtacha kvadratik xatoligini (neg_mean_squared_error) hisoblaydi. Natijada,
# modelning umumiy ishlashini baholash uchun bir qator qiymatlar qaytariladi.

def display_scores(scores):
    print("Scores:", scores)
    print("Mean:", scores.mean())
    print("Std.dev:", scores.std())

# display_scores funksiyasi baholash natijalari (masalan, cross_val_score dan olingan
# mse_scores kabi ballar ro'yxati) berilganida, ularni tushunarli tarzda chiqarish uchun ishlatiladi.

# print("Scores:", scores): Berilgan barcha individual ballarni chop etadi.
# print("Mean:", scores.mean()): Barcha ballarning o'rtachasini hisoblab, chop etadi. Bu modelning o'rtacha ish faoliyatini ko'rsatadi.
# print("Std.dev:", scores.std()): Ballarning standart og'ishini hisoblab, chop etadi. Bu modelning
# baholash natijalarida qanchalik o'zgaruvchan ekanligini ko'rsatadi (ya'ni, natijalar bir-biriga qanchalik yaqin yoki uzoq).

display_scores(np.sqrt(-mse_scores))
# Ushbu kod display_scores(np.sqrt(-mse_scores)) cross_val_score orqali hisoblangan o'rtacha kvadratik xatolar
# (MSE) asosida modelning RMSE (Root Mean Squared Error) qiymatlarini baholaydi va natijalarni tushunarli formatda ko'rsatadi.

# Umuman olganda, bu kod sizning Linear Regression modelingizning har bir cross-validation
# bo'linmasidagi o'rtacha bashorat xatosini (RMSE) hisoblaydi va bu xatolarning umumiy statistikasini ko'rsatadi.

# Umuman olganda Scores da 10 marta qayta hisoblab mean std qiymatlarini chiqarib beradi o'rtacha 71_888 $ ekan xatolik

scores = cross_val_score(RF_model, x_prepared, y, scoring='neg_mean_squared_error', cv=10)
display_scores(np.sqrt(-scores))
display_scores(np.sqrt(-mse_scores))

# Bunda scoring='neg_mean_squared_error' bilan hisoblab o'rtacha 63_745 xatosini chiqardi

"""# **NEW SECTION**

# **6**-**QADAM**

# **TAQDIMOT**

# **Taqdimot.**
# **Modelni saqlab olish**

## pickle
"""

import pickle

filname = 'LR_model.pkl'  # Faylga hohlagancha nom berish mumkin
with open(filname, 'wb') as file:
  pickle.dump(LR_model, file)

# Buni pickle usulida saqladik

with open(filname, 'rb') as file:
  LR_model_loaded = pickle.load(file)

# O'qilmoqda

LR_model_loaded

"""## joblib"""

import joblib

filename = 'LR_model.pkl' # Faylga boshqacha nom berish ham mumkin
joblib.dump(LR_model, filename)

# Bu

model = joblib.load(filename)

scores = cross_val_score(model, x_prepared, y, scoring='neg_mean_squared_error', cv=10)
LR_rmse_scores = np.sqrt(-scores)
display_scores(LR_rmse_scores)

"""Bu kod joblib kutubxonasidan foydalanib mashina o'rganish modelini (LR_model) faylga saqlash va keyinchalik uni yuklash jarayonini amalga oshiradi:

import joblib: joblib kutubxonasini import qiladi. Bu kutubxona Python obyektlarini, ayniqsa NumPy massivlari kabi katta hajmdagi ma'lumotlarga ega bo'lgan ML modellarini samarali saqlash va yuklash uchun mo'ljallangan.
filename = 'LR_model.pkl': Saqlanadigan fayl nomi 'LR_model.pkl' qilib belgilanadi. '.pkl' kengaytmasi odatda 'pickle' formatidagi fayllar uchun ishlatiladi, joblib ham shundan foydalanadi.

joblib.dump(LR_model, filename): Bu qator LR_model nomli mashina o'rganish modelini belgilangan filename (ya'ni 'LR_model.pkl') fayliga saqlaydi. Bu modelni kelajakda qayta ishlatish uchun diskka yozish imkonini beradi, modelni qayta o'qitishga hojat qolmaydi.

model = joblib.load(filename): Bu qator esa avval saqlangan 'LR_model.pkl' faylidan modelni o'qiydi va uni model o'zgaruvchisiga yuklaydi. Endi model o'zgaruvchisidan foydalanib, yuklangan modelni bashorat qilish yoki boshqa vazifalar uchun ishlatish mumkin.

## Loyiha ishi tugadi
"""